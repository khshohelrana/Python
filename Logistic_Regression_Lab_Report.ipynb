{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdS+Y+4tqsINtT+uar5edN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khshohelrana/Python/blob/main/Logistic_Regression_Lab_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Q3BDG0uMw3wa",
        "outputId": "5bf4672b-59c4-4ea8-fefa-1ac197b4d963"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train_scaled' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-efcf254b0fee>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Fit Logistic Regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Predict on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Fit Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_sklearn = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "print(\"Accuracy of logistic regression using scikit-learn:\", accuracy_sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Step 1: Define the logistic function (sigmoid function)\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Step 2: Implement the cost function (binary cross-entropy)\n",
        "def cost_function(X, y, theta):\n",
        "    m = len(y)\n",
        "    h = sigmoid(np.dot(X, theta))\n",
        "    cost = (-1 / m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
        "    return cost\n",
        "\n",
        "# Step 3: Implement gradient descent\n",
        "def gradient_descent(X, y, theta, alpha, iterations):\n",
        "    m = len(y)\n",
        "    costs = []\n",
        "    for i in range(iterations):\n",
        "        h = sigmoid(np.dot(X, theta))\n",
        "        gradient = np.dot(X.T, (h - y)) / m\n",
        "        theta -= alpha * gradient\n",
        "        cost = cost_function(X, y, theta)\n",
        "        costs.append(cost)\n",
        "    return theta, costs\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data[:, [0]]  # Sepal Length\n",
        "y = (iris.target == 0).astype(int)  # Setosa or not\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Add bias term\n",
        "X_train_biased = np.c_[np.ones((X_train_scaled.shape[0], 1)), X_train_scaled]\n",
        "X_test_biased = np.c_[np.ones((X_test_scaled.shape[0], 1)), X_test_scaled]\n",
        "\n",
        "# Initialize parameters\n",
        "theta = np.zeros(X_train_biased.shape[1])\n",
        "\n",
        "# Set hyperparameters\n",
        "alpha = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "# Train the model\n",
        "theta_trained, costs = gradient_descent(X_train_biased, y_train, theta, alpha, iterations)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = np.round(sigmoid(np.dot(X_test_biased, theta_trained)))\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of logistic regression from scratch:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggqR7xtByBiP",
        "outputId": "98117af9-c93f-49ad-c6a7-99899b0a43e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of logistic regression from scratch: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# 2. Implement logistic regression from scratch\n",
        "class LogisticRegressionCustom:\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.num_iterations):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_predicted = self.sigmoid(linear_model)\n",
        "\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
        "\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self.sigmoid(linear_model)\n",
        "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "        return y_predicted_cls\n",
        "\n",
        "# 3. Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data[:, [0, 3]]  # Selecting only Sepal Length and Petal Width\n",
        "y = iris.target\n",
        "\n",
        "# 4. Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Train and evaluate custom logistic regression model\n",
        "model_custom = LogisticRegressionCustom()\n",
        "model_custom.fit(X_train, y_train)\n",
        "y_pred_custom = model_custom.predict(X_test)\n",
        "\n",
        "# 6. Train and evaluate scikit-learn's logistic regression model\n",
        "model_sklearn = LogisticRegression()\n",
        "model_sklearn.fit(X_train, y_train)\n",
        "y_pred_sklearn = model_sklearn.predict(X_test)\n",
        "\n",
        "# 7. Evaluate model performance\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "accuracy_custom, precision_custom, recall_custom, f1_custom = evaluate_model(y_test, y_pred_custom)\n",
        "accuracy_sklearn, precision_sklearn, recall_sklearn, f1_sklearn = evaluate_model(y_test, y_pred_sklearn)\n",
        "\n",
        "# 8. Compare performance\n",
        "print(\"Custom Logistic Regression Performance:\")\n",
        "print(\"Accuracy:\", accuracy_custom)\n",
        "print(\"Precision:\", precision_custom)\n",
        "print(\"Recall:\", recall_custom)\n",
        "print(\"F1 Score:\", f1_custom)\n",
        "print(\"\\n\")\n",
        "print(\"Scikit-Learn's Logistic Regression Performance:\")\n",
        "print(\"Accuracy:\", accuracy_sklearn)\n",
        "print(\"Precision:\", precision_sklearn)\n",
        "print(\"Recall:\", recall_sklearn)\n",
        "print(\"F1 Score:\", f1_sklearn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km5bgI87ylUE",
        "outputId": "3594c03f-cd70-40eb-ec4b-cd1ef4d18cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Logistic Regression Performance:\n",
            "Accuracy: 0.3\n",
            "Precision: 0.09\n",
            "Recall: 0.3\n",
            "F1 Score: 0.13846153846153844\n",
            "\n",
            "\n",
            "Scikit-Learn's Logistic Regression Performance:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Implementing logistic regression from scratch\n",
        "class LogisticRegressionCustom:\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.num_iterations):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_predicted = self.sigmoid(linear_model)\n",
        "\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
        "\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self.sigmoid(linear_model)\n",
        "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "        return y_predicted_cls\n",
        "\n",
        "# Load the Iris dataset and select features\n",
        "iris = load_iris()\n",
        "X = iris.data[:, [0, 3]]  # Selecting only Sepal Length and Petal Width\n",
        "y = (iris.target == 2).astype(int)  # Convert target to binary classification\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and evaluate custom logistic regression model\n",
        "model_custom = LogisticRegressionCustom()\n",
        "model_custom.fit(X_train, y_train)\n",
        "y_pred_custom = model_custom.predict(X_test)\n",
        "\n",
        "# Train and evaluate scikit-learn's logistic regression model\n",
        "model_sklearn = LogisticRegression()\n",
        "model_sklearn.fit(X_train, y_train)\n",
        "y_pred_sklearn = model_sklearn.predict(X_test)\n",
        "\n",
        "# Compare performance\n",
        "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
        "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "\n",
        "print(\"Custom Logistic Regression Accuracy:\", accuracy_custom)\n",
        "print(\"Scikit-Learn's Logistic Regression Accuracy:\", accuracy_sklearn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g_3GezWzJrk",
        "outputId": "e574708c-7187-459e-8f24-4774810aec5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Logistic Regression Accuracy: 0.9333333333333333\n",
            "Scikit-Learn's Logistic Regression Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "#First of all we have to Prepare the data\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, [0, 3]]  # Selecting Sepal Length and Petal Width\n",
        "y = (iris.target == 0).astype(int)  # Iris Setosa is the positive class (1)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "#Secondly here is the Implemented logistic regression from scratch\n",
        "class LogisticRegressionFromScratch:\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.theta = np.zeros(X.shape[1])\n",
        "        m = X.shape[0]\n",
        "\n",
        "        for _ in range(self.num_iterations):\n",
        "            z = np.dot(X, self.theta)\n",
        "            h = self.sigmoid(z)\n",
        "            gradient = np.dot(X.T, (h - y)) / m\n",
        "            self.theta -= self.learning_rate * gradient\n",
        "\n",
        "    def predict(self, X):\n",
        "        z = np.dot(X, self.theta)\n",
        "        return np.round(self.sigmoid(z))\n",
        "\n",
        "# Step 3: Train the logistic regression model using scratch\n",
        "model_scratch = LogisticRegressionFromScratch()\n",
        "model_scratch.fit(X_train_scaled, y_train)\n",
        "predictions_scratch = model_scratch.predict(X_test_scaled)\n",
        "\n",
        "# Step 4: Train a logistic regression model using scikit-learn\n",
        "model_sklearn = LogisticRegression()\n",
        "model_sklearn.fit(X_train_scaled, y_train)\n",
        "predictions_sklearn = model_sklearn.predict(X_test_scaled)\n",
        "\n",
        "# Step 5: Evaluataion methods of  the performance of both models\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "accuracy_scratch, precision_scratch, recall_scratch, f1_scratch = evaluate_model(y_test, predictions_scratch)\n",
        "accuracy_sklearn, precision_sklearn, recall_sklearn, f1_sklearn = evaluate_model(y_test, predictions_sklearn)\n",
        "\n",
        "# Step 6: Comparison the performance of the two models\n",
        "print(\"Performance Metrics for Logistic Regression from Scratch:\")\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy_scratch))\n",
        "print(\"Precision: {:.2f}\".format(precision_scratch))\n",
        "print(\"Recall: {:.2f}\".format(recall_scratch))\n",
        "print(\"F1-score: {:.2f}\".format(f1_scratch))\n",
        "print(\"\\nPerformance Metrics for Logistic Regression using scikit-learn:\")\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy_sklearn))\n",
        "print(\"Precision: {:.2f}\".format(precision_sklearn))\n",
        "print(\"Recall: {:.2f}\".format(recall_sklearn))\n",
        "print(\"F1-score: {:.2f}\".format(f1_sklearn))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1XrHYzW07ml",
        "outputId": "011b3150-3b41-464f-9faa-049d3d8445e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Metrics for Logistic Regression from Scratch:\n",
            "Accuracy: 0.91\n",
            "Precision: 0.83\n",
            "Recall: 1.00\n",
            "F1-score: 0.90\n",
            "\n",
            "Performance Metrics for Logistic Regression using scikit-learn:\n",
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-score: 1.00\n"
          ]
        }
      ]
    }
  ]
}